# RAG Search System

**Purpose:** Semantic search across files and emails using vector embeddings
**Technology:** Hybrid search (BM25 keyword + pgvector similarity + RRF fusion)
**Models:** OpenAI text-embedding-3-small (embeddings) + Claude Haiku (reranking)
**MCP Tool:** `search_files`, `search_emails`, `get_file_content`
**Status:** Production, actively used

---

## Table of Contents

1. [Overview](#overview)
2. [How It Works](#how-it-works)
3. [Hybrid Search Architecture](#hybrid-search-architecture)
4. [Vector Embeddings](#vector-embeddings)
5. [File Search](#file-search)
6. [Email Search](#email-search)
7. [LLM Reranking](#llm-reranking)
8. [Performance Optimization](#performance-optimization)
9. [Usage Examples](#usage-examples)
10. [Troubleshooting](#troubleshooting)

---

## Overview

RAG (Retrieval-Augmented Generation) enables **semantic search** across your knowledge base. Instead of keyword matching, it understands meaning.

### Traditional Search vs RAG

**Traditional (Keyword):**
```
Query: "cost-effective treatment"
Results: Documents containing exact words "cost", "effective", "treatment"
Misses: "economical therapy", "affordable care", "value-based medicine"
```

**RAG (Semantic):**
```
Query: "cost-effective treatment"
Results:
  1. "Economic evaluation of burn care" (similarity: 0.89)
  2. "Value-based pricing strategies" (similarity: 0.84)
  3. "Budget impact analysis of new therapies" (similarity: 0.81)
```

RAG finds documents by **meaning**, not just exact keywords.

### Core Concepts

**1. Embeddings**
- Numerical representations of text (1536-dimensional vectors)
- Similar meanings → similar vectors
- Generated by OpenAI text-embedding-3-small model

**2. Vector Similarity**
- Cosine similarity: measures angle between vectors
- Score 0-1: higher = more similar
- Uses pgvector extension in PostgreSQL

**3. Chunking**
- Large documents split into smaller pieces
- Enables precise retrieval (specific sections)
- Hierarchical structure preserved

**4. Hybrid Search**
- Combines keyword matching (BM25) + semantic search (vector)
- RRF (Reciprocal Rank Fusion) merges results
- Best of both worlds: exact matches + conceptual matches

---

## How It Works

### End-to-End Flow

```
┌────────────────────────────────────────────────────────┐
│ 1. USER QUERY                                           │
│    "Find documents about patient outcomes"             │
└────────────────────────────────────────────────────────┘
                          ↓
┌────────────────────────────────────────────────────────┐
│ 2. GENERATE QUERY EMBEDDING                            │
│    OpenAI API → [0.123, -0.456, 0.789, ...]          │
│    (1536-dimensional vector)                           │
└────────────────────────────────────────────────────────┘
                          ↓
┌────────────────────────────────────────────────────────┐
│ 3. HYBRID SEARCH                                        │
│    ┌────────────────────────────────────────────────┐ │
│    │ A. Keyword Search (BM25)                       │ │
│    │    SELECT * FROM file_chunks                   │ │
│    │    WHERE to_tsvector(content)                  │ │
│    │          @@ plainto_tsquery('patient outcomes')│ │
│    │    ORDER BY ts_rank(...) DESC                  │ │
│    │    → Results: [doc1, doc5, doc12]              │ │
│    └────────────────────────────────────────────────┘ │
│                                                         │
│    ┌────────────────────────────────────────────────┐ │
│    │ B. Vector Search (Cosine Similarity)           │ │
│    │    SELECT * FROM file_chunks                   │ │
│    │    ORDER BY embedding <=> $query_embedding     │ │
│    │    LIMIT 50                                     │ │
│    │    → Results: [doc1, doc3, doc7]               │ │
│    └────────────────────────────────────────────────┘ │
│                                                         │
│    ┌────────────────────────────────────────────────┐ │
│    │ C. RRF Fusion                                  │ │
│    │    Combine results from A and B                │ │
│    │    Score = 1/(k + rank_A) + 1/(k + rank_B)   │ │
│    │    k = 60 (constant)                           │ │
│    │    → Merged: [doc1, doc3, doc5, doc7, doc12]  │ │
│    └────────────────────────────────────────────────┘ │
└────────────────────────────────────────────────────────┘
                          ↓
┌────────────────────────────────────────────────────────┐
│ 4. LLM RERANKING (Optional)                            │
│    Claude Haiku scores top 20 results                  │
│    ├─ "How relevant is this chunk to the query?"      │
│    ├─ Score 0-10 per result                            │
│    └─ Re-sort by relevance score                       │
│    → Final: [doc3, doc1, doc7, doc5]                  │
└────────────────────────────────────────────────────────┘
                          ↓
┌────────────────────────────────────────────────────────┐
│ 5. FORMAT & RETURN                                     │
│    1. Clinical_Outcomes.pdf (Similarity: 92%)         │
│       Section: Patient-Reported Outcomes              │
│       "Patients showed significant improvement..."     │
│                                                        │
│    2. Efficacy_Analysis.docx (Similarity: 87%)        │
│       Section: Results > Primary Endpoint             │
│       "The primary outcome measure demonstrated..."    │
└────────────────────────────────────────────────────────┘
```

---

## Hybrid Search Architecture

### Why Hybrid?

**Vector-only search:**
- ✅ Finds conceptual matches
- ✅ Handles synonyms well
- ❌ Misses exact keyword matches
- ❌ Poor with proper nouns (project codes, names)

**Keyword-only search:**
- ✅ Fast exact matches
- ✅ Great with specific terms
- ❌ Misses synonyms
- ❌ No semantic understanding

**Hybrid search:**
- ✅ Combines both strengths
- ✅ Better accuracy than either alone
- ✅ Handles edge cases (rare terms + concepts)

### Implementation

**PostgreSQL Extensions:**

```sql
-- Vector similarity (pgvector)
CREATE EXTENSION IF NOT EXISTS vector;

-- Full-text search (built-in)
CREATE EXTENSION IF NOT EXISTS pg_trgm;
```

**Hybrid Query:**

```typescript
async function hybridSearch(query: string, limit: number = 10) {
  // 1. Generate query embedding
  const queryEmbedding = await generateEmbedding(query);

  // 2. BM25 keyword search
  const keywordResults = await sql`
    SELECT
      id,
      file_id,
      content,
      heading_path,
      ts_rank_cd(to_tsvector('english', content), plainto_tsquery('english', ${query})) AS bm25_score,
      ROW_NUMBER() OVER (ORDER BY ts_rank_cd(to_tsvector('english', content), plainto_tsquery('english', ${query})) DESC) AS bm25_rank
    FROM file_chunks
    WHERE to_tsvector('english', content) @@ plainto_tsquery('english', ${query})
    LIMIT 50
  `;

  // 3. Vector similarity search
  const vectorResults = await sql`
    SELECT
      id,
      file_id,
      content,
      heading_path,
      1 - (embedding <=> ${sql.vector(queryEmbedding)}) AS similarity,
      ROW_NUMBER() OVER (ORDER BY embedding <=> ${sql.vector(queryEmbedding)}) AS vector_rank
    FROM file_chunks
    WHERE embedding IS NOT NULL
    ORDER BY embedding <=> ${sql.vector(queryEmbedding)}
    LIMIT 50
  `;

  // 4. Reciprocal Rank Fusion (RRF)
  const k = 60; // Standard RRF constant
  const scores = new Map<string, number>();

  // Add keyword scores
  keywordResults.forEach(r => {
    const score = 1 / (k + r.bm25_rank);
    scores.set(r.id, (scores.get(r.id) || 0) + score);
  });

  // Add vector scores
  vectorResults.forEach(r => {
    const score = 1 / (k + r.vector_rank);
    scores.set(r.id, (scores.get(r.id) || 0) + score);
  });

  // 5. Merge and sort by RRF score
  const merged = [...new Set([...keywordResults, ...vectorResults])].map(r => ({
    ...r,
    rrf_score: scores.get(r.id) || 0,
  }));

  merged.sort((a, b) => b.rrf_score - a.rrf_score);

  return merged.slice(0, limit);
}
```

**RRF Formula:**

```
RRF_score = Σ (1 / (k + rank_i))

Where:
- k = 60 (constant, balances precision/recall)
- rank_i = rank in search method i
- Σ = sum over all search methods

Example:
Document ranked #3 in keyword search, #7 in vector search:
RRF = 1/(60+3) + 1/(60+7) = 0.0159 + 0.0149 = 0.0308
```

Documents appearing in both searches get higher scores.

---

## Vector Embeddings

### Generation

**Model:** OpenAI text-embedding-3-small
**Dimensions:** 1536
**Cost:** $0.02 per 1M tokens (~$0.0001 per document)

**API Call:**

```typescript
async function generateEmbedding(text: string): Promise<number[]> {
  const response = await fetch('https://api.openai.com/v1/embeddings', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      model: 'text-embedding-3-small',
      input: text.slice(0, 8000), // Max ~8K chars per request
    }),
  });

  const data = await response.json();
  return data.data[0].embedding; // [1536 floats]
}
```

**Storage:**

```sql
-- Files table (document-level embeddings)
ALTER TABLE files ADD COLUMN embedding vector(1536);

-- File chunks table (chunk-level embeddings)
ALTER TABLE file_chunks ADD COLUMN embedding vector(1536);

-- Emails table
ALTER TABLE email_logs ADD COLUMN embedding vector(1536);

-- Create indexes for fast similarity search
CREATE INDEX files_embedding_idx ON files USING ivfflat (embedding vector_cosine_ops)
  WITH (lists = 100);

CREATE INDEX file_chunks_embedding_idx ON file_chunks USING ivfflat (embedding vector_cosine_ops)
  WITH (lists = 500);
```

**Index Types:**

- **ivfflat:** Approximate nearest neighbor (faster, slight accuracy loss)
- **lists:** Number of clusters (more = better accuracy, slower search)
- **vector_cosine_ops:** Cosine similarity distance metric

### Batch Processing

Embeddings generated in batches for efficiency:

```typescript
const BATCH_SIZE = 100;
const batches = chunk(chunksWithoutEmbeddings, BATCH_SIZE);

for (const batch of batches) {
  // Single API call for entire batch
  const response = await fetch('https://api.openai.com/v1/embeddings', {
    method: 'POST',
    body: JSON.stringify({
      model: 'text-embedding-3-small',
      input: batch.map(c => c.content), // Array of strings
    }),
  });

  const embeddings = response.data;

  // Update all chunks in batch
  for (let i = 0; i < batch.length; i++) {
    await sql`
      UPDATE file_chunks SET
        embedding = ${sql.vector(embeddings[i].embedding)},
        embedded_at = NOW()
      WHERE id = ${batch[i].id}
    `;
  }
}
```

**Rate Limits:**
- 3,000 requests per minute (OpenAI)
- ~300,000 tokens per batch (100 chunks × ~3,000 tokens)

---

## File Search

### `search_files` Tool

**MCP Server:** pai-rag-search
**Exposed in:** LibreChat, Claude Code, Telegram (via API)

**Parameters:**

| Parameter | Type | Description | Default |
|-----------|------|-------------|---------|
| `query` | string | Natural language search query | Required |
| `limit` | number | Max results to return | 5 |
| `folder` | string | Filter by folder path | None |
| `fileType` | string | Filter by extension (pdf, docx, etc.) | None |
| `daysAgo` | number | Only files updated within N days | None |
| `minSimilarity` | number | Minimum similarity threshold (0-1) | 0 |
| `rerank` | boolean | Enable LLM reranking | true (if limit ≤ 10) |

**Example Usage:**

```typescript
// LibreChat
const results = await search_files({
  query: "cost-effectiveness analysis for burn treatment",
  limit: 10,
  folder: "CTS010",
  fileType: "pdf",
  rerank: true,
});

// Returns:
// [
//   {
//     filename: "CTS010_Deliverable_Q4.pdf",
//     heading_path: "Methods > Economic Evaluation > Cost-Effectiveness",
//     content: "The cost-effectiveness analysis was conducted from a healthcare system perspective...",
//     similarity: 0.94,
//     file_path: "C:\\Users\\oscar\\Nextcloud\\Areas\\Work\\CTS010 denovoSkin\\Deliverables\\CTS010_Deliverable_Q4.pdf",
//     level: "chunk",
//   },
//   // ... more results
// ]
```

### Search Levels

**Document-level search:**
- Searches entire files (using file.embedding)
- Returns whole document
- Use when: broad topic search ("all documents about denovoSkin")

**Chunk-level search (default):**
- Searches individual sections (using file_chunks.embedding)
- Returns specific paragraphs/sections
- Use when: precise information needed ("cost-effectiveness methodology")

**Implementation:**

```typescript
// Chunk-level (default)
const results = await sql`
  SELECT
    c.id,
    c.content,
    c.heading_path,
    f.filename,
    f.file_path,
    1 - (c.embedding <=> ${sql.vector(queryEmbedding)}) as similarity
  FROM file_chunks c
  JOIN files f ON c.file_id = f.id
  WHERE c.embedding IS NOT NULL
  ORDER BY c.embedding <=> ${sql.vector(queryEmbedding)}
  LIMIT ${limit}
`;

// Document-level (for broad search)
const results = await sql`
  SELECT
    f.filename,
    f.content_summary,
    f.file_path,
    1 - (f.embedding <=> ${sql.vector(queryEmbedding)}) as similarity
  FROM files f
  WHERE f.embedding IS NOT NULL
  ORDER BY f.embedding <=> ${sql.vector(queryEmbedding)}
  LIMIT ${limit}
`;
```

### Filters

**Folder Filter:**

```typescript
// Narrows search to specific project
const results = await search_files({
  query: "deliverable status",
  folder: "CTS010", // Only searches CTS010 project files
});

// SQL WHERE clause:
WHERE f.file_path LIKE '%CTS010%'
```

**File Type Filter:**

```typescript
// Only PDFs
const results = await search_files({
  query: "presentation slides",
  fileType: "pdf",
});

// SQL WHERE clause:
WHERE f.file_type = 'pdf'
```

**Date Filter:**

```typescript
// Only recent files
const results = await search_files({
  query: "latest analysis",
  daysAgo: 7, // Last week only
});

// SQL WHERE clause:
WHERE f.updated_at > NOW() - INTERVAL '7 days'
```

---

## Email Search

### `search_emails` Tool

**Purpose:** Semantic search across emails (not files)
**Scope:** Only actionable/informational emails (excludes promotional, junk)

**Parameters:**

| Parameter | Type | Description | Default |
|-----------|------|-------------|---------|
| `query` | string | Natural language search query | Required |
| `limit` | number | Max results to return | 5 |
| `minSimilarity` | number | Minimum similarity threshold | 0.3 |

**Example:**

```typescript
const results = await search_emails({
  query: "meeting with Ben about denovoSkin deliverable",
  limit: 10,
});

// Returns:
// [
//   {
//     subject: "DenovoSkin Q4 Review",
//     sender_name: "Ben Wilding",
//     sender_email: "ben@cogentia.co.uk",
//     received_at: "2026-02-04T10:30:00Z",
//     extraction_summary: "Meeting request to discuss Q4 deliverable timeline",
//     snippet: "Hi Oscar, can we catch up about the denovoSkin deliverable?...",
//     similarity: 0.89,
//   },
//   // ... more results
// ]
```

### Email Filtering

**Included categories:**
- actionable
- informational

**Excluded categories:**
- promotional
- junk
- subscription

**SQL:**

```sql
SELECT
  subject,
  sender_name,
  sender_email,
  received_at,
  extraction_summary,
  snippet,
  1 - (embedding <=> $1::vector) as similarity
FROM email_logs
WHERE category IN ('actionable', 'informational')
  AND embedding IS NOT NULL
  AND 1 - (embedding <=> $1::vector) > 0.3
ORDER BY similarity DESC
LIMIT 10
```

---

## LLM Reranking

### Why Rerank?

Vector similarity alone can miss nuances:
- Query: "budget impact analysis"
- Result 1: "The budget for this project is..." (high similarity, wrong context)
- Result 2: "Budget impact analysis methodology..." (medium similarity, correct context)

LLM reranking uses Claude Haiku to **read each result and score relevance**.

### When Reranking Runs

**Automatic triggers:**
- `limit ≤ 10` (default: enabled)
- `rerank=true` explicitly set

**Disabled:**
- `limit > 10` (too expensive)
- `rerank=false` explicitly set

### Implementation

```typescript
async function rerankResults(query: string, results: SearchResult[]): Promise<SearchResult[]> {
  // Only rerank top 20 (cost limit)
  const toRerank = results.slice(0, 20);

  // Build prompt
  const prompt = `Rate the relevance of each document to this query:

QUERY: "${query}"

DOCUMENTS:
${toRerank.map((r, i) => `
${i + 1}. ${r.filename}
Section: ${r.heading_path || 'N/A'}
Content: ${r.content.slice(0, 500)}...
`).join('\n')}

For each document, provide a relevance score 0-10:
- 10 = Perfect match, directly answers query
- 7-9 = Highly relevant, contains key information
- 4-6 = Somewhat relevant, mentions related topics
- 1-3 = Barely relevant, only tangentially related
- 0 = Not relevant

OUTPUT (JSON):
{ "scores": [8, 10, 5, 9, 3, ...] }`;

  const response = await fetch('https://openrouter.ai/api/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${process.env.OPENROUTER_API_KEY}`,
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      model: 'anthropic/claude-3.5-haiku',
      messages: [{ role: 'user', content: prompt }],
    }),
  });

  const data = await response.json();
  const scores = JSON.parse(data.choices[0].message.content).scores;

  // Assign scores and re-sort
  toRerank.forEach((r, i) => {
    r.rerank_score = scores[i];
  });

  toRerank.sort((a, b) => b.rerank_score - a.rerank_score);

  // Merge with non-reranked results
  return [...toRerank, ...results.slice(20)];
}
```

**Cost:**
- ~$0.001 per rerank (20 results)
- Claude 3.5 Haiku: $0.80 input / $4 output per M tokens
- ~1,000 tokens per rerank call

---

## Performance Optimization

### Current Performance

**Query Latency:**
- Vector search only: ~50-100ms
- Hybrid search: ~100-200ms
- With LLM reranking: ~2-3 seconds

**Database Size:**
- Files indexed: 73
- Chunks: 2,908
- Emails: ~900 (actionable/informational)

**Embedding Coverage:**
- Files: 100% (73/73)
- Chunks: 97.5% (2,836/2,908)
- Emails: ~95%

### Index Optimization

**IVFFlat Index:**

```sql
-- Current configuration
CREATE INDEX file_chunks_embedding_idx ON file_chunks
  USING ivfflat (embedding vector_cosine_ops)
  WITH (lists = 500);
```

**Tuning `lists` parameter:**
- Too few lists (100): Fast but less accurate
- Too many lists (1000): Accurate but slow
- Sweet spot: sqrt(row_count) (e.g., 500 for 250K rows)

**Rebuild index periodically:**

```sql
-- After adding many new chunks
REINDEX INDEX file_chunks_embedding_idx;
```

### Query Optimization

**Limit scan range:**

```sql
-- Bad: scans all chunks
SELECT * FROM file_chunks
ORDER BY embedding <=> $1
LIMIT 10;

-- Good: filters first, then sorts
SELECT * FROM file_chunks
WHERE file_id IN (
  SELECT id FROM files WHERE folder LIKE '%CTS010%'
)
ORDER BY embedding <=> $1
LIMIT 10;
```

**Prefilter with folder/type:**

```typescript
// More efficient
await search_files({
  query: "deliverable",
  folder: "CTS010", // Reduces search space
  limit: 5,
});

// vs scanning all 2,908 chunks
await search_files({
  query: "deliverable",
  limit: 5,
});
```

### Caching

**Query cache (future enhancement):**

```typescript
// Cache query embeddings for common queries
const cache = new Map<string, number[]>();

async function getCachedEmbedding(query: string): Promise<number[]> {
  if (cache.has(query)) {
    return cache.get(query)!;
  }

  const embedding = await generateEmbedding(query);
  cache.set(query, embedding);
  return embedding;
}
```

**Benefits:**
- Reduces OpenAI API calls
- Saves ~50-100ms per repeated query
- Useful for common searches ("show my tasks", "latest deliverable")

---

## Usage Examples

### Finding Documents by Topic

```typescript
// Broad topic search
const results = await search_files({
  query: "health technology assessment methodology",
  limit: 10,
});

// Returns documents about HTA methods across all projects
```

### Project-Specific Search

```typescript
// Narrow to specific project
const results = await search_files({
  query: "patient outcomes",
  folder: "CTS010",
  limit: 5,
});

// Only searches CTS010 denovoSkin project files
```

### Recent Documents Only

```typescript
// Last week's work
const results = await search_files({
  query: "analysis results",
  daysAgo: 7,
  limit: 10,
});

// Good for: "What did I work on recently?"
```

### Specific File Types

```typescript
// Only presentations
const results = await search_files({
  query: "client presentation",
  fileType: "pptx",
  limit: 5,
});
```

### Email Archaeology

```typescript
// Find old emails about topic
const results = await search_emails({
  query: "budget discussion with Sarah",
  limit: 10,
});

// Returns emails mentioning budget + Sarah
```

### Get Full Document

```typescript
// After finding file in search
const content = await get_file_content({
  filename: "CTS010_Deliverable_Q4.pdf",
  maxLength: 50000,
});

// Returns full extracted content
```

### Get Specific Section

```typescript
// Retrieve just one section
const content = await get_file_content({
  filename: "CTS010_Deliverable_Q4.pdf",
  section: "Cost-Effectiveness Analysis",
  maxLength: 10000,
});

// Returns only matching section
```

---

## Troubleshooting

### No Results Found

**Symptoms:**
- Search returns empty
- Files exist but not found

**Diagnosis:**

1. **Check embeddings:**
   ```sql
   SELECT
     COUNT(*) as total,
     COUNT(*) FILTER (WHERE embedding IS NOT NULL) as embedded,
     ROUND(100.0 * COUNT(*) FILTER (WHERE embedding IS NOT NULL) / COUNT(*), 1) as coverage_pct
   FROM file_chunks;
   ```

2. **Check query:**
   - Try broader terms
   - Check spelling

3. **Lower similarity threshold:**
   ```typescript
   const results = await search_files({
     query: "...",
     minSimilarity: 0, // Accept any match
   });
   ```

4. **Check folder filter:**
   - Remove folder filter
   - Verify folder name correct

**Common Causes:**

1. **Embeddings missing:** Run `bun run scripts/generate-embeddings.ts`
2. **Query too specific:** Use broader terms
3. **Wrong folder:** Check actual file location in database
4. **Typo in query:** Fix spelling

---

### Poor Result Quality

**Symptoms:**
- Irrelevant results ranked high
- Relevant results ranked low

**Solutions:**

1. **Enable reranking:**
   ```typescript
   const results = await search_files({
     query: "...",
     rerank: true, // LLM scores relevance
   });
   ```

2. **More specific query:**
   ```
   ❌ "analysis"
   ✅ "cost-effectiveness analysis for burn treatment"
   ```

3. **Add filters:**
   ```typescript
   const results = await search_files({
     query: "deliverable",
     folder: "CTS010",
     fileType: "pdf",
     daysAgo: 30,
   });
   ```

4. **Increase similarity threshold:**
   ```typescript
   const results = await search_files({
     query: "...",
     minSimilarity: 0.7, // Only high-quality matches
   });
   ```

---

### Slow Search

**Symptoms:**
- Queries take >5 seconds
- Timeout errors

**Diagnosis:**

1. **Check index:**
   ```sql
   SELECT * FROM pg_indexes
   WHERE tablename = 'file_chunks'
     AND indexname LIKE '%embedding%';
   ```

2. **Check database size:**
   ```sql
   SELECT
     COUNT(*) as chunks,
     pg_size_pretty(pg_total_relation_size('file_chunks')) as size
   FROM file_chunks;
   ```

3. **Profile query:**
   ```sql
   EXPLAIN ANALYZE
   SELECT * FROM file_chunks
   ORDER BY embedding <=> '[...]'::vector
   LIMIT 10;
   ```

**Solutions:**

1. **Rebuild index:**
   ```sql
   REINDEX INDEX file_chunks_embedding_idx;
   ```

2. **Adjust lists parameter:**
   ```sql
   DROP INDEX file_chunks_embedding_idx;
   CREATE INDEX file_chunks_embedding_idx ON file_chunks
     USING ivfflat (embedding vector_cosine_ops)
     WITH (lists = 1000); -- More lists = slower but more accurate
   ```

3. **Disable reranking:**
   ```typescript
   const results = await search_files({
     query: "...",
     rerank: false, // Skip LLM step
   });
   ```

---

### Embedding Generation Failed

**Symptoms:**
- New files not searchable
- `embedding` column NULL

**Diagnosis:**

```sql
SELECT
  filename,
  embedded_at,
  processing_status
FROM files
WHERE embedding IS NULL
  AND processing_status = 'processed';
```

**Solutions:**

1. **Run embedding script:**
   ```bash
   cd ~/.claude/tools
   bun run scripts/generate-embeddings.ts --files
   ```

2. **Check OpenAI API key:**
   ```bash
   curl https://api.openai.com/v1/embeddings \
     -H "Authorization: Bearer $OPENAI_API_KEY" \
     -H "Content-Type: application/json" \
     -d '{"model":"text-embedding-3-small","input":"test"}'
   ```

3. **Check quota:**
   - OpenAI dashboard → Usage
   - May have hit rate limit or quota

---

## Best Practices

### Query Formulation

**Be specific:**
```
❌ "documents"
✅ "cost-effectiveness analysis documents for CTS010"
```

**Use natural language:**
```
❌ "cost AND effectiveness AND (burn OR wound)"
✅ "cost-effectiveness of burn wound treatment"
```

**Include context:**
```
❌ "results"
✅ "clinical trial results for patient outcomes"
```

### Filter Usage

**Start broad, then narrow:**
```typescript
// 1. Broad search
let results = await search_files({ query: "deliverable" });

// 2. If too many results, add filters
results = await search_files({
  query: "deliverable",
  folder: "CTS010",
  daysAgo: 30,
});
```

### Reranking Strategy

**Enable for precision-critical queries:**
```typescript
// Important analysis
const results = await search_files({
  query: "methodology for economic evaluation",
  rerank: true, // Worth the 2-3 second cost
});
```

**Disable for speed-critical queries:**
```typescript
// Quick lookup
const results = await search_files({
  query: "latest presentation",
  rerank: false, // Fast results
});
```

---

## Related Documentation

- [File Processing](./file-processing.md) - How files become searchable
- [Email System](./email-system.md) - How emails are indexed
- [Database Schema](../04-development/database-schema.md) - Files and chunks tables
- [MCP Tools Reference](../06-reference/mcp-tools.md) - Complete tool documentation
- [LibreChat](./librechat.md) - Using RAG search in web UI
- [Telegram Bot](./telegram-bot.md) - Using RAG search via mobile
